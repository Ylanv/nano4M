+ cat /var/spool/slurmd/job2602670/slurm_script
+ export MASTER_PORT=25678
+ MASTER_PORT=25678
++ hostname
+ export MASTER_ADDR=i05
+ MASTER_ADDR=i05
+ export WANDB_API_KEY=7457be928b9e92a9434d2a7c069cc345d39a8c3e
+ WANDB_API_KEY=7457be928b9e92a9434d2a7c069cc345d39a8c3e
+ export NCCL_DEBUG=INFO
+ NCCL_DEBUG=INFO
+ source /work/com-304/new_environment/anaconda3/etc/profile.d/conda.sh
++ export CONDA_EXE=/work/com-304/new_environment/anaconda3/bin/conda
++ CONDA_EXE=/work/com-304/new_environment/anaconda3/bin/conda
++ export _CE_M=
++ _CE_M=
++ export _CE_CONDA=
++ _CE_CONDA=
++ export CONDA_PYTHON_EXE=/work/com-304/new_environment/anaconda3/bin/python
++ CONDA_PYTHON_EXE=/work/com-304/new_environment/anaconda3/bin/python
++ '[' -z x ']'
+ conda init
+ local cmd=init
+ case "$cmd" in
+ __conda_exe init
+ /work/com-304/new_environment/anaconda3/bin/conda init
+ conda activate nanofm
+ local cmd=activate
+ case "$cmd" in
+ __conda_activate activate nanofm
+ '[' -n '' ']'
+ local ask_conda
++ PS1=
++ __conda_exe shell.posix activate nanofm
++ /work/com-304/new_environment/anaconda3/bin/conda shell.posix activate nanofm
+ ask_conda='. "/work/com-304/new_environment/anaconda3/etc/conda/deactivate.d/libglib_deactivate.sh"
PS1='\''(nanofm) '\''
export PATH='\''/ssoft/spack/syrah/v2/opt/spack/linux-rhel9-x86_64_v2/gcc-11.2.1/tmux-3.2a-u4p5zsufbl7j7nuevapic7pe5xrbx6ee/bin:/home/vifian/.vscode-server/bin/863d2581ecda6849923a2118d93a088b0745d9d6/bin/remote-cli:/work/com-304/new_environment/anaconda3/envs/nanofm/bin:/work/com-304/new_environment/anaconda3/condabin:/home/vifian/.local/bin:/home/vifian/bin:/usr/lib64/ccache:/usr/local/bin:/usr/bin:/usr/local/sbin:/usr/sbin:/opt/puppetlabs/bin'\''
export CONDA_PREFIX='\''/work/com-304/new_environment/anaconda3/envs/nanofm'\''
export CONDA_SHLVL='\''4'\''
export CONDA_DEFAULT_ENV='\''nanofm'\''
export CONDA_PROMPT_MODIFIER='\''(nanofm) '\''
export CONDA_PREFIX_3='\''/work/com-304/new_environment/anaconda3'\''
export CONDA_EXE='\''/work/com-304/new_environment/anaconda3/bin/conda'\''
export _CE_M='\'''\''
export _CE_CONDA='\'''\''
export CONDA_PYTHON_EXE='\''/work/com-304/new_environment/anaconda3/bin/python'\'''
+ eval '. "/work/com-304/new_environment/anaconda3/etc/conda/deactivate.d/libglib_deactivate.sh"
PS1='\''(nanofm) '\''
export PATH='\''/ssoft/spack/syrah/v2/opt/spack/linux-rhel9-x86_64_v2/gcc-11.2.1/tmux-3.2a-u4p5zsufbl7j7nuevapic7pe5xrbx6ee/bin:/home/vifian/.vscode-server/bin/863d2581ecda6849923a2118d93a088b0745d9d6/bin/remote-cli:/work/com-304/new_environment/anaconda3/envs/nanofm/bin:/work/com-304/new_environment/anaconda3/condabin:/home/vifian/.local/bin:/home/vifian/bin:/usr/lib64/ccache:/usr/local/bin:/usr/bin:/usr/local/sbin:/usr/sbin:/opt/puppetlabs/bin'\''
export CONDA_PREFIX='\''/work/com-304/new_environment/anaconda3/envs/nanofm'\''
export CONDA_SHLVL='\''4'\''
export CONDA_DEFAULT_ENV='\''nanofm'\''
export CONDA_PROMPT_MODIFIER='\''(nanofm) '\''
export CONDA_PREFIX_3='\''/work/com-304/new_environment/anaconda3'\''
export CONDA_EXE='\''/work/com-304/new_environment/anaconda3/bin/conda'\''
export _CE_M='\'''\''
export _CE_CONDA='\'''\''
export CONDA_PYTHON_EXE='\''/work/com-304/new_environment/anaconda3/bin/python'\'''
++ . /work/com-304/new_environment/anaconda3/etc/conda/deactivate.d/libglib_deactivate.sh
+++ export GSETTINGS_SCHEMA_DIR=
+++ GSETTINGS_SCHEMA_DIR=
+++ unset GSETTINGS_SCHEMA_DIR_CONDA_BACKUP
+++ '[' -z ']'
+++ unset GSETTINGS_SCHEMA_DIR
++ PS1='(nanofm) '
++ export PATH=/ssoft/spack/syrah/v2/opt/spack/linux-rhel9-x86_64_v2/gcc-11.2.1/tmux-3.2a-u4p5zsufbl7j7nuevapic7pe5xrbx6ee/bin:/home/vifian/.vscode-server/bin/863d2581ecda6849923a2118d93a088b0745d9d6/bin/remote-cli:/work/com-304/new_environment/anaconda3/envs/nanofm/bin:/work/com-304/new_environment/anaconda3/condabin:/home/vifian/.local/bin:/home/vifian/bin:/usr/lib64/ccache:/usr/local/bin:/usr/bin:/usr/local/sbin:/usr/sbin:/opt/puppetlabs/bin
++ PATH=/ssoft/spack/syrah/v2/opt/spack/linux-rhel9-x86_64_v2/gcc-11.2.1/tmux-3.2a-u4p5zsufbl7j7nuevapic7pe5xrbx6ee/bin:/home/vifian/.vscode-server/bin/863d2581ecda6849923a2118d93a088b0745d9d6/bin/remote-cli:/work/com-304/new_environment/anaconda3/envs/nanofm/bin:/work/com-304/new_environment/anaconda3/condabin:/home/vifian/.local/bin:/home/vifian/bin:/usr/lib64/ccache:/usr/local/bin:/usr/bin:/usr/local/sbin:/usr/sbin:/opt/puppetlabs/bin
++ export CONDA_PREFIX=/work/com-304/new_environment/anaconda3/envs/nanofm
++ CONDA_PREFIX=/work/com-304/new_environment/anaconda3/envs/nanofm
++ export CONDA_SHLVL=4
++ CONDA_SHLVL=4
++ export CONDA_DEFAULT_ENV=nanofm
++ CONDA_DEFAULT_ENV=nanofm
++ export 'CONDA_PROMPT_MODIFIER=(nanofm) '
++ CONDA_PROMPT_MODIFIER='(nanofm) '
++ export CONDA_PREFIX_3=/work/com-304/new_environment/anaconda3
++ CONDA_PREFIX_3=/work/com-304/new_environment/anaconda3
++ export CONDA_EXE=/work/com-304/new_environment/anaconda3/bin/conda
++ CONDA_EXE=/work/com-304/new_environment/anaconda3/bin/conda
++ export _CE_M=
++ _CE_M=
++ export _CE_CONDA=
++ _CE_CONDA=
++ export CONDA_PYTHON_EXE=/work/com-304/new_environment/anaconda3/bin/python
++ CONDA_PYTHON_EXE=/work/com-304/new_environment/anaconda3/bin/python
+ __conda_hashr
+ '[' -n '' ']'
+ '[' -n '' ']'
+ hash -r
+ srun bash -c '
  TORCHRUN_ARGS="--node-rank=${SLURM_PROCID}      --master-addr=${MASTER_ADDR}      --master-port=${MASTER_PORT}      --nnodes=${SLURM_NNODES}      --nproc-per-node=2"

  echo ${SLURM_PROCID}
  echo ${TORCHRUN_ARGS}
  echo ${SLURMD_NODENAME}

  torchrun ${TORCHRUN_ARGS} run_training.py     --config cfgs/nano4M/multiclevr_d6-6w512.yaml
'
W0417 11:51:31.609000 3011857 site-packages/torch/distributed/run.py:792] 
W0417 11:51:31.609000 3011857 site-packages/torch/distributed/run.py:792] *****************************************
W0417 11:51:31.609000 3011857 site-packages/torch/distributed/run.py:792] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
W0417 11:51:31.609000 3011857 site-packages/torch/distributed/run.py:792] *****************************************
W0417 11:51:32.021000 2502781 site-packages/torch/distributed/run.py:792] 
W0417 11:51:32.021000 2502781 site-packages/torch/distributed/run.py:792] *****************************************
W0417 11:51:32.021000 2502781 site-packages/torch/distributed/run.py:792] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
W0417 11:51:32.021000 2502781 site-packages/torch/distributed/run.py:792] *****************************************
[rank2]:[W417 11:51:37.147974602 ProcessGroupNCCL.cpp:4561] [PG ID 0 PG GUID 0 Rank 2]  using GPU 0 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. Specify device_ids in barrier() to force use of a particular device, or call init_process_group() with a device_id.
[rank3]:[W417 11:51:37.152433394 ProcessGroupNCCL.cpp:4561] [PG ID 0 PG GUID 0 Rank 3]  using GPU 1 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. Specify device_ids in barrier() to force use of a particular device, or call init_process_group() with a device_id.
[rank1]:[W417 11:51:38.108203875 ProcessGroupNCCL.cpp:4561] [PG ID 0 PG GUID 0 Rank 1]  using GPU 1 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. Specify device_ids in barrier() to force use of a particular device, or call init_process_group() with a device_id.
[rank0]:[W417 11:51:38.108215870 ProcessGroupNCCL.cpp:4561] [PG ID 0 PG GUID 0 Rank 0]  using GPU 0 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. Specify device_ids in barrier() to force use of a particular device, or call init_process_group() with a device_id.
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ylanv (scoobyfam) to https://api.wandb.ai. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.19.8
wandb: Run data is saved locally in /home/vifian/COM-304-FM/com-304-FM-project/nano4M/wandb/run-20250417_115139-a2yqs1vp
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run multiclevr_d6-6w512
wandb: ‚≠êÔ∏è View project at https://wandb.ai/scoobyfam/fourm
wandb: üöÄ View run at https://wandb.ai/scoobyfam/fourm/runs/a2yqs1vp
/work/com-304/new_environment/anaconda3/envs/nanofm/lib/python3.10/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers
  warnings.warn(f"Importing from {__name__} is deprecated, please import via timm.layers", FutureWarning)
/work/com-304/new_environment/anaconda3/envs/nanofm/lib/python3.10/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers
  warnings.warn(f"Importing from {__name__} is deprecated, please import via timm.layers", FutureWarning)
/work/com-304/new_environment/anaconda3/envs/nanofm/lib/python3.10/site-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 10 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(
/work/com-304/new_environment/anaconda3/envs/nanofm/lib/python3.10/site-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 10 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(
/work/com-304/new_environment/anaconda3/envs/nanofm/lib/python3.10/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers
  warnings.warn(f"Importing from {__name__} is deprecated, please import via timm.layers", FutureWarning)
/work/com-304/new_environment/anaconda3/envs/nanofm/lib/python3.10/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers
  warnings.warn(f"Importing from {__name__} is deprecated, please import via timm.layers", FutureWarning)
/work/com-304/new_environment/anaconda3/envs/nanofm/lib/python3.10/site-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 10 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(
/work/com-304/new_environment/anaconda3/envs/nanofm/lib/python3.10/site-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 10 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(
[rank2]:[W417 16:30:21.658000913 ProcessGroupNCCL.cpp:1496] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
[rank0]:[W417 16:30:26.891811264 ProcessGroupNCCL.cpp:1496] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
