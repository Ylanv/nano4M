model:
  n_mels: 80
  embedding_dim: 64
  codebook_size: 512

train:
  batch_size: 32
  lr: 0.001
  epochs: 50
  log_interval: 100
  save_dir: checkpoints/

data:
  dataset_path: data/LibriSpeech/train-clean-100
  sample_rate: 16000
  chunk_duration: 2.0  # seconds
